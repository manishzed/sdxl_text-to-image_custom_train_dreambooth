# -*- coding: utf-8 -*-
"""text-to-image_custom_stableDiffusion_DreamBooth.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aidCfkm0SNO4C305Q9-npED4oLJSP1ME
"""

!nvidia-smi

# Commented out IPython magic to ensure Python compatibility.
# %pip install -U autotrain-advanced

!rm -rf /content/Dreambooth_SDXL

PROJECT_NAME = "Dreambooth_SDXL"
MODEL_NAME = "stabilityai/stable-diffusion-xl-base-1.0"
DATA_DIR = "/content/manish_photos"
REPO_ID = "kr-manish/text-to-image-sdxl-lora-manish"

from PIL import Image

def image_grid(imgs, rows, cols, resize=256):
    assert len(imgs) == rows * cols

    if resize is not None:
        imgs = [img.resize((resize, resize)) for img in imgs]

    w, h = imgs[0].size
    grid_w, grid_h = cols * w, rows * h
    grid = Image.new("RGB", size=(grid_w, grid_h))

    for i, img in enumerate(imgs):
        x = i % cols * w
        y = i // cols * h
        grid.paste(img, box=(x, y))

    return grid

import glob

imgs = [Image.open(path) for path in glob.glob("/content/manish_photos/*.png")]
image_grid(imgs, 1, 7)

from huggingface_hub import notebook_login
notebook_login()

#!rm -rf /content/manish_photos

!autotrain dreambooth \
--model $MODEL_NAME \
--project-name $PROJECT_NAME \
--image-path $DATA_DIR \
--prompt "A photo of manish kumar wearing casual clothes, taking a selfie, and smiling." \
--resolution 1024 \
--batch-size 1 \
--num-steps 300 \
--gradient-accumulation 4 \
--lr 1e-4 \
--fp16 \
--gradient-checkpointing \
--push-to-hub \
--repo-id $REPO_ID

from diffusers import DiffusionPipeline, AutoencoderKL, StableDiffusionXLImg2ImgPipeline

import torch

vae = AutoencoderKL.from_pretrained(
    "madebyollin/sdxl-vae-fp16-fix",
    torch_dtype=torch.float16
)
pipe = DiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0",
    vae=vae,
    torch_dtype=torch.float16,
    variant="fp16",
    use_safetensors=True,
)
pipe.to("cuda");
#pipe.load_lora_weights(REPO_ID, weight_name="pytorch_lora_weights.safetensors")
pipe.load_lora_weights("/content/Dreambooth_SDXL", weight_name="/content/Dreambooth_SDXL/pytorch_lora_weights.safetensors")


prompt = "A photo of manish kumar participating in a marathon."

image = pipe(prompt=prompt, num_inference_steps=25, num_images_per_prompt = 3)
image_grid(image.images, 1, 3)

import gc
gc.collect()
torch.cuda.empty_cache()

#prompt = "A photo of manish kumar giving a press conference."
prompt = "A photo of manish kumar waring  a indian army clothes."

image = pipe(prompt=prompt, num_inference_steps=25, num_images_per_prompt = 3)
image_grid(image.images, 1, 3)

prompt = "A photo of manish kumar swimming in bikni."

seed = 65
generator = torch.Generator("cuda").manual_seed(seed)
image = pipe(prompt=prompt, num_inference_steps=25, generator=generator).images[0]
image.resize((300, 300))

refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-refiner-1.0",
    vae=vae,
    torch_dtype=torch.float16,
    use_safetensors=True,
    variant="fp16",
)
refiner.to("cuda");

image = refiner(prompt=prompt, num_inference_steps=25, generator=generator, image=image)
image.images[0].resize((300, 300))





